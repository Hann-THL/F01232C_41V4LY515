{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Raise warning as error to capture floating-point errors during computation:\n",
    "# https://stackoverflow.com/questions/34955158/what-might-be-the-cause-of-invalid-value-encountered-in-less-equal-in-numpy/34955622\n",
    "# https://www.soa.org/news-and-publications/newsletters/compact/2014/may/com-2014-iss51/losing-my-precision-tips-for-handling-tricky-floating-point-arithmetic/\n",
    "import numpy as np\n",
    "np.seterr(all='raise')\n",
    "\n",
    "# Plotly\n",
    "from plotly.offline import iplot, plot, init_notebook_mode\n",
    "import plotly.graph_objects as go\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "# Time measurement\n",
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "import os\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Sound notification\n",
    "import winsound\n",
    "\n",
    "# Profiling\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_PATH_DATA = 'resources/data/'\n",
    "OUT_PATH_GRAPH = 'resources/output/graph/'\n",
    "OUT_PATH_FILE = 'resources/output/file/'\n",
    "\n",
    "def create_directory(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "def plot_graph(data, title, xlabel=None, ylabel=None, generate_file=True):\n",
    "    layout = go.Layout(\n",
    "        title = title,\n",
    "        xaxis = dict(\n",
    "            title=xlabel,\n",
    "            gridcolor='rgb(159, 197, 232)'\n",
    "        ),\n",
    "        yaxis = dict(\n",
    "            title=ylabel,\n",
    "            gridcolor='rgb(159, 197, 232)'\n",
    "        ),\n",
    "        hovermode='x',\n",
    "        showlegend=True,\n",
    "        legend_orientation='h',\n",
    "        plot_bgcolor='rgba(0, 0, 0, 0)'\n",
    "    )\n",
    "\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    fig.update_yaxes(hoverformat=\".5f\")\n",
    "\n",
    "    if generate_file:\n",
    "        generate_plot(fig, f'{OUT_PATH_GRAPH}', f'{title}.html')\n",
    "    else:\n",
    "        generate_plot(fig)\n",
    "\n",
    "def generate_plot(fig, out_path=None, out_filename=None):\n",
    "    if out_path is None:\n",
    "        iplot(fig)\n",
    "    else:\n",
    "        create_directory(out_path)\n",
    "        out_file = f'{out_path}{out_filename}'\n",
    "        plot(fig, filename=out_file, auto_open=False)\n",
    "        \n",
    "        print(f'Generated: {out_file}')\n",
    "\n",
    "def generate_csv(df, out_path, out_filename, export_index=None):\n",
    "    create_directory(out_path)\n",
    "    out_file = f'{out_path}{out_filename}'\n",
    "    df.to_csv(out_file, sep=';', index=export_index, header=True)\n",
    "    \n",
    "    print(f'Generated: {out_file}')\n",
    "\n",
    "def time_taken(seconds):\n",
    "    print(f'\\nTime Taken: {str(timedelta(seconds=seconds))}')\n",
    "    winsound.Beep(frequency=1000, duration=100)\n",
    "    winsound.Beep(frequency=1500, duration=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForexEnv:\n",
    "    def __init__(self, source_path, filename, nrows=None, train_size=.7, train=True):\n",
    "        source_path = SOURCE_PATH_DATA\n",
    "        filename    = f'DAT_ASCII_{currency_pair}_T_201901.csv'\n",
    "        self.__train_test_split(source_path, filename, nrows=nrows, train_size=train_size, train=train)\n",
    "        \n",
    "    def __train_test_split(self, source_path, filename, chunk_size=50_000, nrows=None, train_size=.7, train=True):\n",
    "        source_file = f'{source_path}{filename}'\n",
    "        df_chunks = pd.read_csv(source_file, sep=',',\n",
    "                                header=None, names=['datetime', 'bid', 'ask', 'vol'],\n",
    "                                usecols=['datetime', 'bid', 'ask'],\n",
    "                                parse_dates=['datetime'],\n",
    "                                date_parser=lambda x: pd.to_datetime(x, format=\"%Y%m%d %H%M%S%f\"),\n",
    "                                chunksize=chunk_size, nrows=nrows)\n",
    "        timeseries_df = pd.concat(df_chunks)\n",
    "        \n",
    "        row_count  = len(timeseries_df) if nrows is None else nrows\n",
    "        split_size = round(row_count * train_size)\n",
    "        \n",
    "        if train:\n",
    "            timeseries_df = timeseries_df[:split_size].reset_index().drop(columns=['index'])\n",
    "        else:\n",
    "            timeseries_df = timeseries_df[split_size:].reset_index().drop(columns=['index'])\n",
    "        \n",
    "        self.indexes   = timeseries_df.index.values\n",
    "        self.datetimes = timeseries_df['datetime'].values\n",
    "        self.bids      = timeseries_df['bid'].values\n",
    "        self.asks      = timeseries_df['ask'].values\n",
    "        \n",
    "    def constant_values(self):\n",
    "        return {\n",
    "            'TRADE_STATUS': {\n",
    "                'OPEN': 'OPEN',\n",
    "                'CLOSE': 'CLOSED',\n",
    "                'CLOSE_TRADE': 'CLOSE_TRADE'\n",
    "            },\n",
    "            'TRADE_ACTION': {\n",
    "                'BUY': 0,\n",
    "                'SELL': 1,\n",
    "                'HOLD': 2\n",
    "            }\n",
    "        }\n",
    "        \n",
    "    def state_space(self):\n",
    "        return np.array(['entry_action', 'bid_fluctuation_pct', 'ask_fluctuation_pct'])\n",
    "        \n",
    "    def state_size(self):\n",
    "        return len(self.state_space())\n",
    "        \n",
    "    def action_space(self):\n",
    "        const_action_dict = self.constant_values()['TRADE_ACTION']\n",
    "        return [const_action_dict['BUY'], const_action_dict['SELL'], const_action_dict['HOLD']]\n",
    "        \n",
    "    def action_size(self):\n",
    "        return len(self.action_space())\n",
    "        \n",
    "    def available_actions(self):\n",
    "        const_status_dict = self.constant_values()['TRADE_STATUS']\n",
    "        actions = self.action_space()\n",
    "        \n",
    "        # Have open trades\n",
    "        trade_dict = self.trading_params_dict['trade_dict']\n",
    "        if const_status_dict['OPEN'] in trade_dict['status']:\n",
    "            open_index  = trade_dict['status'].index(const_status_dict['OPEN'])\n",
    "            open_action = trade_dict['action'][open_index]\n",
    "\n",
    "            # Ensure agent is able to have only 1 open trade while trading\n",
    "            actions.remove(open_action)\n",
    "        return actions\n",
    "    \n",
    "    def __price_by_action(self, action, bid, ask, closed_trade):\n",
    "        const_action_dict = self.constant_values()['TRADE_ACTION']\n",
    "        \n",
    "        # Close trade by Selling at Ask price, and Buying at Bid price\n",
    "        if closed_trade:\n",
    "            return bid if action == const_action_dict['BUY'] else ask\n",
    "        \n",
    "        # Open trade by Buying at Ask price, and Selling at Bid price\n",
    "        else:\n",
    "            return ask if action == const_action_dict['BUY'] else bid\n",
    "    \n",
    "    def __profit_by_action(self, entry_action, entry_price, curr_bid, curr_ask):\n",
    "        const_action_dict = self.constant_values()['TRADE_ACTION']\n",
    "        if entry_action == const_action_dict['BUY']:\n",
    "            return curr_ask - entry_price\n",
    "        \n",
    "        elif entry_action == const_action_dict['SELL']:\n",
    "            return entry_price - curr_bid\n",
    "        return 0\n",
    "    \n",
    "    def update_timestep(self, index):\n",
    "        try:\n",
    "            self.timestep = {\n",
    "                'index': self.indexes[index],\n",
    "                'datetime': self.datetimes[index],\n",
    "                'bid': self.bids[index],\n",
    "                'ask': self.asks[index]\n",
    "            }\n",
    "            return False\n",
    "        \n",
    "        except:\n",
    "            self.timestep = {}\n",
    "            return True\n",
    "    \n",
    "    def reset(self):\n",
    "        # State\n",
    "        self.default_entry_action        = -1 # np.inf # None\n",
    "        self.default_bid_fluctuation_pct = -0. # np.inf # None\n",
    "        self.default_ask_fluctuation_pct = -0. # np.inf # None\n",
    "        \n",
    "        entry_action        = self.default_entry_action\n",
    "        bid_fluctuation_pct = self.default_bid_fluctuation_pct\n",
    "        ask_fluctuation_pct = self.default_ask_fluctuation_pct\n",
    "        self.observe_bid    = None\n",
    "        self.observe_ask    = None\n",
    "        self.state = np.array([entry_action, bid_fluctuation_pct, ask_fluctuation_pct])\n",
    "        \n",
    "        # Timestep\n",
    "        index = 0\n",
    "        self.update_timestep(index)\n",
    "        \n",
    "        # Trading\n",
    "        self.trading_params_dict = {\n",
    "            'orig_bal': 1_000_000.,\n",
    "            'acct_bal': 1_000_000.,\n",
    "            'unit':     100_000.,\n",
    "            \n",
    "            'trade_dict': {\n",
    "                'action':   [],\n",
    "                'datetime': [],\n",
    "                'price':    [],\n",
    "                'status':   [],\n",
    "                'profits':  [],\n",
    "                'acct_bal': []\n",
    "            }\n",
    "        }\n",
    "        return self.state\n",
    "    \n",
    "    def step(self, action):\n",
    "        const_action_dict = self.constant_values()['TRADE_ACTION']\n",
    "        const_status_dict = self.constant_values()['TRADE_STATUS']\n",
    "        \n",
    "        self.observe_bid = self.timestep['bid'] if self.observe_bid is None else self.observe_bid\n",
    "        self.observe_ask = self.timestep['ask'] if self.observe_ask is None else self.observe_ask\n",
    "        \n",
    "        trade_dict = self.trading_params_dict['trade_dict']\n",
    "        \n",
    "        # Get entry action & price\n",
    "        # - if there's no entry action, treat current action as action to open a trade\n",
    "        # - if there's entry action, treat current action as action to close a trade\n",
    "        try:\n",
    "            # NOTE: not to use pd.DataFrame() to convert trade_dict to dataframe, as it is slower\n",
    "            open_index      = trade_dict['status'].index(const_status_dict['OPEN'])\n",
    "            trade_actions   = trade_dict['action'][open_index:]\n",
    "            trade_prices    = trade_dict['price'][open_index:]\n",
    "            trade_datetimes = trade_dict['datetime'][open_index:]\n",
    "            \n",
    "            entry_action = trade_actions[0]\n",
    "            \n",
    "            # Not allowed to close open trades with same entry action\n",
    "            if entry_action == action:\n",
    "                trade_actions  = []\n",
    "                trade_prices   = []\n",
    "                trade_datetime = []\n",
    "            \n",
    "        except:\n",
    "            trade_actions  = []\n",
    "            trade_prices   = []\n",
    "            trade_datetime = []\n",
    "\n",
    "            entry_action = self.default_entry_action\n",
    "        \n",
    "        \n",
    "        profit = 0\n",
    "        closed_trade = False\n",
    "        sufficient_margin = True\n",
    "        if action in [const_action_dict['BUY'], const_action_dict['SELL']]:\n",
    "            # Close open trades\n",
    "            for trade_index, trade_price in enumerate(trade_prices):\n",
    "                profit += self.__profit_by_action(entry_action, trade_price, self.timestep['bid'], self.timestep['ask'])\n",
    "                profit *= self.trading_params_dict['unit']\n",
    "                profit = round(profit, 5)\n",
    "                \n",
    "                trade_dict['status'][trade_dict['datetime'].index(trade_datetimes[trade_index])] = const_status_dict['CLOSE']\n",
    "                closed_trade = True\n",
    "\n",
    "            # Add trade transaction\n",
    "            self.trading_params_dict['acct_bal'] += profit\n",
    "            price = self.__price_by_action(action, self.timestep['bid'], self.timestep['ask'], closed_trade)\n",
    "\n",
    "            # Add back free margin upon close trade\n",
    "            if closed_trade:\n",
    "                self.trading_params_dict['acct_bal'] += (len(trade_prices) * self.trading_params_dict['unit'])\n",
    "                \n",
    "            # Deduct required margin upon opening trade\n",
    "            else:\n",
    "                required_margin = self.trading_params_dict['unit']\n",
    "                if self.trading_params_dict['acct_bal'] < required_margin:\n",
    "                    sufficient_margin = False\n",
    "                self.trading_params_dict['acct_bal'] -= required_margin\n",
    "            \n",
    "            \n",
    "            trade_dict['action'].append(action)\n",
    "            trade_dict['datetime'].append(self.timestep['datetime'])\n",
    "            trade_dict['price'].append(price)\n",
    "            trade_dict['status'].append(const_status_dict['CLOSE_TRADE'] if closed_trade else const_status_dict['OPEN'])\n",
    "            trade_dict['profits'].append(profit)\n",
    "            trade_dict['acct_bal'].append(round(self.trading_params_dict['acct_bal'], 5))\n",
    "        \n",
    "        \n",
    "        # Calculate floating P/L\n",
    "#         float_profit = 0\n",
    "#         if (entry_action != self.default_entry_action) & (not closed_trade):\n",
    "#             for trade_index, trade_price in enumerate(trade_prices):\n",
    "#                 float_profit = self.__profit_by_action(entry_action, trade_price, self.timestep['bid'], self.timestep['ask'])\n",
    "#                 float_profit *= self.trading_params_dict['unit']\n",
    "#                 float_profit = round(float_profit, 5)\n",
    "        \n",
    "        # Calculate equity %\n",
    "#         equity_pct = (self.trading_params_dict['acct_bal'] + float_profit) / self.trading_params_dict['orig_bal'] * 100\n",
    "#         equity_pct = round(equity_pct, 10)\n",
    "        \n",
    "        # Observe the price at current timestemp if open or closed trades, else observe the entry price\n",
    "        self.observe_bid = self.timestep['bid'] if closed_trade else self.observe_bid if action == const_action_dict['HOLD'] else self.timestep['bid']\n",
    "        self.observe_ask = self.timestep['ask'] if closed_trade else self.observe_ask if action == const_action_dict['HOLD'] else self.timestep['ask']\n",
    "        \n",
    "        # Calculate fluctuation %\n",
    "        bid_fluctuation_pct = round((self.timestep['bid'] - self.observe_bid) / self.observe_bid, 5)\n",
    "        ask_fluctuation_pct = round((self.timestep['ask'] - self.observe_ask) / self.observe_ask, 5)\n",
    "        \n",
    "        \n",
    "        # State\n",
    "        state_entry_action = self.default_entry_action if closed_trade else self.state[0] if action == const_action_dict['HOLD'] else action\n",
    "        next_state = np.array([state_entry_action, bid_fluctuation_pct, ask_fluctuation_pct])\n",
    "        \n",
    "        # Reward\n",
    "        reward = profit\n",
    "        \n",
    "        done = self.update_timestep(self.timestep['index'] +1)\n",
    "        if not done:\n",
    "            # Stop trading if do not have balance, and there's no open trade\n",
    "            if (self.trading_params_dict['acct_bal'] <= self.trading_params_dict['unit']) & (const_status_dict['OPEN'] not in trade_dict['status']):\n",
    "                done = True\n",
    "                \n",
    "            # Stop trading if do not have enough balance to pay for required margin\n",
    "            elif not sufficient_margin:\n",
    "                done = True\n",
    "        \n",
    "        # Additional information\n",
    "        info_dict = {\n",
    "            'closed_trade': closed_trade,\n",
    "            'sufficient_margin': sufficient_margin\n",
    "        }\n",
    "        return (next_state, reward, done, info_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixModel:\n",
    "    def __init__(self, action_size, init_value=.0):\n",
    "        self.action_size = action_size\n",
    "        self.init_value  = init_value\n",
    "        \n",
    "        self.states = np.empty((0, self.action_size))\n",
    "        self.values = np.empty((0, self.action_size))\n",
    "        \n",
    "    def state_values(self, state):\n",
    "        try:\n",
    "            index  = self.states.tolist().index(state.tolist())\n",
    "            values = self.values[index]\n",
    "        except:\n",
    "            self.states = np.append(self.states, [state], axis=0)\n",
    "            self.values = np.append(self.values, [[self.init_value for _ in range(self.action_size)]], axis=0)\n",
    "            values      = self.state_values(state)\n",
    "            \n",
    "        return values\n",
    "    \n",
    "    def state_action_value(self, state, action):\n",
    "        values = self.state_values(state)\n",
    "        return values[action]\n",
    "    \n",
    "    def set_state_action(self, state, action, value):\n",
    "        values = self.state_values(state)\n",
    "        values[action] = value\n",
    "        \n",
    "        # No need to update array as it's modified on referencing variable\n",
    "        # index = self.states.tolist().index(state.tolist())\n",
    "        # self.values[index] = values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, env):\n",
    "        self.hyperparams_dict = {\n",
    "            'epsilon': {\n",
    "                'min': np.nan, 'max': np.nan, 'decay': np.nan, 'value': np.nan\n",
    "            },\n",
    "            'alpha': {\n",
    "                'min': np.nan, 'max': np.nan, 'decay': np.nan, 'value': np.nan\n",
    "            },\n",
    "            'gamma': {\n",
    "                'min': np.nan, 'max': np.nan, 'increase': np.nan, 'value': np.nan\n",
    "            }\n",
    "        }\n",
    "        self.env = env\n",
    "        \n",
    "    def choose_action(self, state):\n",
    "        return random.choice(self.env.available_actions())\n",
    "    \n",
    "    def learn(self, experience, next_action, episode):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Off-Policy Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q-Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QMatrixAgent(Agent):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        \n",
    "        self.hyperparams_dict = {\n",
    "            'epsilon': {\n",
    "                'min': .1, 'max': 1., 'decay': .005, 'value': 1.\n",
    "            },\n",
    "            'alpha': {\n",
    "                'min': .001, 'max': .9, 'decay': .005, 'value': .9\n",
    "            },\n",
    "            'gamma': {\n",
    "                'min': .9, 'max': .9, 'increase': .0, 'value': .9\n",
    "            }\n",
    "        }\n",
    "        self.env = env\n",
    "        self.main_model = self.build_model(env.state_size(), env.action_size())\n",
    "        \n",
    "    def build_model(self, state_size, action_size, init_value=.0):\n",
    "        return MatrixModel(action_size, init_value)\n",
    "    \n",
    "    def __random_argmax(self, q_values, random_if_empty=False):\n",
    "        # Reference:\n",
    "        # https://gist.github.com/stober/1943451\n",
    "        indexes = np.nonzero(q_values == np.amax(q_values))[0]\n",
    "        \n",
    "        try:\n",
    "            return np.random.choice(indexes)\n",
    "        except TypeOfError as error:\n",
    "            if not random_if_empty:\n",
    "                raise Exception(error)\n",
    "                \n",
    "            return np.random.choice(indexes if indexes.size > 0 else q_values.size)\n",
    "        \n",
    "    def choose_action(self, state):\n",
    "        # Exploration\n",
    "        if np.random.uniform(0, 1) <= self.hyperparams_dict['epsilon']['value']:\n",
    "            return random.choice(self.env.available_actions())\n",
    "        \n",
    "        # Exploitation\n",
    "        else:\n",
    "            # Perform exploration if specific state does not have Q-value\n",
    "            try:\n",
    "                q_values = self.main_model.state_values(state).copy()\n",
    "            except:\n",
    "                return random.choice(self.env.available_actions())\n",
    "            \n",
    "            # Validation whether action with highest Q-value is valid\n",
    "            actions      = self.env.action_space()\n",
    "            action_index = self.__random_argmax(q_values)\n",
    "            action       = actions[action_index]\n",
    "            \n",
    "            if action not in self.env.available_actions():\n",
    "                # Remove action if it's not a valid action on current state\n",
    "                q_values = np.delete(q_values, action_index)\n",
    "                del actions[action_index]\n",
    "\n",
    "                # Select action with 2nd highest Q-value\n",
    "                action_index = self.__random_argmax(q_values)\n",
    "                action       = actions[action_index]\n",
    "\n",
    "            return action\n",
    "        \n",
    "    def adjust_hyperparams(self, param_name, episode):\n",
    "        if param_name in ['epsilon', 'alpha']:\n",
    "            min_value = self.hyperparams_dict[param_name]['min']\n",
    "            max_value = self.hyperparams_dict[param_name]['max']\n",
    "            rate      = self.hyperparams_dict[param_name]['decay']\n",
    "        \n",
    "        elif param_name == 'gamma':\n",
    "            # Swap min. max. for incrementing\n",
    "            min_value = self.hyperparams_dict[param_name]['max']\n",
    "            max_value = self.hyperparams_dict[param_name]['min']\n",
    "            rate      = self.hyperparams_dict[param_name]['increase']\n",
    "            \n",
    "        self.hyperparams_dict[param_name]['value'] = min_value + (max_value - min_value) * np.exp(-rate * episode)\n",
    "        \n",
    "    def learn(self, experience, next_action, episode):\n",
    "        state, action, reward, next_state, done = experience\n",
    "        \n",
    "        # Q[s, a] = Q[s, a] + alpha * (reward + gamma * Max[Q(s’, A)] - Q[s, a])\n",
    "        max_q_value = np.max(self.main_model.state_values(next_state))\n",
    "        q_value = self.main_model.state_action_value(state, action)\n",
    "        q_value = q_value + self.hyperparams_dict['alpha']['value'] * (reward + self.hyperparams_dict['gamma']['value'] * max_q_value - q_value)\n",
    "        self.main_model.set_state_action(state, action, round(q_value, 10))\n",
    "        \n",
    "        # Adjust hyperparameters\n",
    "        if done:\n",
    "            self.adjust_hyperparams('epsilon', episode)\n",
    "            self.adjust_hyperparams('alpha', episode)\n",
    "            self.adjust_hyperparams('gamma', episode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q-Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Q-Network (DQN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Double DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dueling Double DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On-Policy Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SARSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SarsaAgent(QMatrixAgent):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        \n",
    "    def learn(self, experience, next_action, episode):\n",
    "        state, action, reward, next_state, done = experience\n",
    "        \n",
    "        # Q[s, a] = Q[s, a] + alpha * (reward + gamma * Q(s’, a’) - Q[s, a])\n",
    "        next_q_value = self.main_model.state_action_value(next_state, next_action)\n",
    "        q_value = self.main_model.state_action_value(state, action)\n",
    "        q_value = q_value + self.hyperparams_dict['alpha']['value'] * (reward + self.hyperparams_dict['gamma']['value'] * next_q_value - q_value)\n",
    "        self.main_model.set_state_action(state, action, round(q_value, 10))\n",
    "        \n",
    "        # Adjust hyperparameters\n",
    "        if done:\n",
    "            self.adjust_hyperparams('epsilon', episode)\n",
    "            self.adjust_hyperparams('alpha', episode)\n",
    "            self.adjust_hyperparams('gamma', episode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SARSA (λ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SarsaLambdaAgent(SarsaAgent):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        \n",
    "        # Eligibility Trace params\n",
    "        self.hyperparams_dict['elig_trace'] = {\n",
    "            'init': 1 / env.action_size(),\n",
    "            'lambda': .9\n",
    "        }\n",
    "        self.e_model = self.__build_e_model()\n",
    "        \n",
    "    def __build_e_model(self):\n",
    "        return self.build_model(env.state_size(), env.action_size(),\n",
    "                                init_value=self.hyperparams_dict['elig_trace']['init'])\n",
    "        \n",
    "    def learn(self, experience, next_action, episode):\n",
    "        state, action, reward, next_state, done = experience\n",
    "        \n",
    "        # Reference:\n",
    "        # https://naifmehanna.com/2018-10-18-implementing-sarsa-in-python/\n",
    "        next_q_value = self.main_model.state_action_value(next_state, next_action)\n",
    "        q_value = self.main_model.state_action_value(state, action)\n",
    "        \n",
    "        # Ensure state added to main model is added to elibility trace as well\n",
    "        self.e_model.state_action_value(next_state, next_action)\n",
    "        e_value = self.e_model.state_action_value(state, action)\n",
    "        self.e_model.set_state_action(state, action, e_value +1)\n",
    "        \n",
    "        states_q_values = self.main_model.values\n",
    "        states_e_values = self.e_model.values\n",
    "        \n",
    "        # Calculate & Update Q-matrix\n",
    "        states_q_values = states_q_values + self.hyperparams_dict['alpha']['value'] * (reward + self.hyperparams_dict['gamma']['value'] * next_q_value - q_value) * states_e_values\n",
    "        self.main_model.values = np.round(states_q_values, 10)\n",
    "        \n",
    "        # Decay & Update E-matrix\n",
    "        states_e_values = states_e_values * self.hyperparams_dict['gamma']['value'] * self.hyperparams_dict['elig_trace']['lambda']\n",
    "        self.e_model.values = np.round(states_e_values, 10)\n",
    "        \n",
    "        # Adjust hyperparameters\n",
    "        if done:\n",
    "            self.adjust_hyperparams('epsilon', episode)\n",
    "            self.adjust_hyperparams('alpha', episode)\n",
    "            self.adjust_hyperparams('gamma', episode)\n",
    "            \n",
    "            # Re-initialize Eligibility Trace on each episode:\n",
    "            # https://stackoverflow.com/questions/29904270/eligibility-trace-reinitialization-between-episodes-in-sarsa-lambda-implementati\n",
    "            self.e_model = self.__build_e_model()\n",
    "            self.e_model.states = self.main_model.states.copy()\n",
    "            self.e_model.values = np.full(self.e_model.states.shape, self.hyperparams_dict['elig_trace']['init'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "currency_pair = 'EURUSD'\n",
    "filename      = f'DAT_ASCII_{currency_pair}_T_201901.csv'\n",
    "\n",
    "env = ForexEnv(SOURCE_PATH_DATA, filename, nrows=200, train_size=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(episodes, agent_type):\n",
    "    # Off-Policy agent\n",
    "    if agent_type == 'Normal':\n",
    "        agent = Agent(env)\n",
    "        \n",
    "    elif agent_type == 'Q-Matrix':\n",
    "        agent = QMatrixAgent(env)\n",
    "        \n",
    "    # On-Policy agent\n",
    "    elif agent_type == 'SARSA':\n",
    "        agent = SarsaAgent(env)\n",
    "        \n",
    "    elif agent_type == 'SARSA Lambda':\n",
    "        agent = SarsaLambdaAgent(env)\n",
    "    \n",
    "    \n",
    "    # Performance tracking\n",
    "    result_dict = {\n",
    "        'total_profit': [],\n",
    "        'used_margin': [],\n",
    "        'acct_bal': [],\n",
    "        'trades': []\n",
    "    }\n",
    "\n",
    "    # Training iteration\n",
    "    for episode in range(episodes):\n",
    "        # Walkthrough environment\n",
    "        done = False\n",
    "        state = env.reset()\n",
    "        action = agent.choose_action(state)\n",
    "\n",
    "        while not done:\n",
    "            # Take action\n",
    "            next_state, reward, done, info_dict = env.step(action)\n",
    "            \n",
    "            # Choose next action\n",
    "            next_action = agent.choose_action(next_state)\n",
    "            \n",
    "            # Learning\n",
    "            agent.learn((state, action, reward, next_state, done), next_action, episode)\n",
    "            \n",
    "            state  = next_state\n",
    "            action = next_action\n",
    "\n",
    "        # Result Summary\n",
    "        trade_df      = pd.DataFrame(env.trading_params_dict['trade_dict'])\n",
    "        total_profits = sum(trade_df['profits'])\n",
    "\n",
    "        open_trade_df = trade_df[trade_df['status'].isin([env.constant_values()['TRADE_STATUS']['OPEN']])]\n",
    "        used_margin   = sum(open_trade_df['price'] * env.trading_params_dict['unit'])\n",
    "\n",
    "        result_dict['total_profit'].append(round(total_profits, 5))\n",
    "        result_dict['used_margin'].append(round(used_margin, 5))\n",
    "        result_dict['acct_bal'].append(round(env.trading_params_dict['acct_bal'], 5))\n",
    "        result_dict['trades'].append(env.trading_params_dict['trade_dict'])\n",
    "\n",
    "        # Progress\n",
    "        clear_output(wait=True)\n",
    "        ε = agent.hyperparams_dict['epsilon']['value']\n",
    "        α = agent.hyperparams_dict['alpha']['value']\n",
    "        γ = agent.hyperparams_dict['gamma']['value']\n",
    "        print(f'EP: {episode+1 :,} / {episodes :,} | ε: {ε :.5f} | α: {α :.5f} | γ: {γ :.5f} | R: {total_profits :,.5f}')\n",
    "        \n",
    "    return result_dict, agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "EXEC_START = time.time()\n",
    "\n",
    "# agent_type = 'Normal'\n",
    "# agent_type = 'Q-Matrix'\n",
    "# agent_type = 'SARSA'\n",
    "agent_type = 'SARSA Lambda'\n",
    "episodes = 5_000\n",
    "\n",
    "# FOR PROFILING PURPOSE\n",
    "# %lprun -f train \\\n",
    "result_dict, agent = train(episodes, agent_type)\n",
    "\n",
    "EXEC_END = time.time()\n",
    "time_taken(EXEC_END - EXEC_START)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trade_df = pd.DataFrame(result_dict['trades'][0])\n",
    "trade_df = pd.DataFrame(result_dict['trades'][len(result_dict['trades']) -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chart: Training Rolling Profits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXEC_START = time.time()\n",
    "\n",
    "\n",
    "data = []\n",
    "data.append(go.Scattergl(\n",
    "    x = [x+1 for x in range(episodes)],\n",
    "    y = pd.DataFrame({\n",
    "        'rolling_profit': result_dict['total_profit']\n",
    "    }).rolling(100).mean()['rolling_profit'],\n",
    "    mode = 'lines',\n",
    "    name = 'Rolling Profits'\n",
    "))\n",
    "\n",
    "title = f'{currency_pair} - Training Rolling Profits - {agent_type}'\n",
    "plot_graph(data, title, 'Episode', 'Amount')\n",
    "\n",
    "\n",
    "EXEC_END = time.time()\n",
    "time_taken(EXEC_END - EXEC_START)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chart: Training Equity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXEC_START = time.time()\n",
    "\n",
    "\n",
    "data = []\n",
    "data.append(go.Scattergl(\n",
    "    x = [x+1 for x in range(episodes)],\n",
    "    y = np.array(result_dict['acct_bal']) + np.array(result_dict['used_margin']),\n",
    "    mode = 'lines',\n",
    "    name = 'Equity'\n",
    "))\n",
    "\n",
    "title = f'{currency_pair} - Training Equity - {agent_type}'\n",
    "plot_graph(data, title, 'Episode', 'Equity')\n",
    "\n",
    "\n",
    "EXEC_END = time.time()\n",
    "time_taken(EXEC_END - EXEC_START)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chart: Training Trades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXEC_START = time.time()\n",
    "\n",
    "\n",
    "data = []\n",
    "price_types = ['bid', 'ask']\n",
    "for price_index, prices in enumerate([env.bids, env.asks]):\n",
    "    data.append(go.Scattergl(\n",
    "        x = pd.DataFrame(env.datetimes)[0],\n",
    "        y = prices,\n",
    "        mode = 'lines',\n",
    "        name = price_types[price_index].title(),\n",
    "        \n",
    "        # Additional settings\n",
    "        hoverinfo='skip'\n",
    "    ))\n",
    "\n",
    "markers = ['triangle-up', 'triangle-down']\n",
    "trade_actions = ['buy', 'sell']\n",
    "for trade_index, trade_action in enumerate(trade_actions):\n",
    "    action_df = trade_df[trade_df['action'] == trade_index]\n",
    "    \n",
    "    data.append(go.Scattergl(\n",
    "        x = action_df['datetime'],\n",
    "        y = action_df['price'],\n",
    "        mode = 'markers',\n",
    "        name = trade_action.title(),\n",
    "        \n",
    "        # Additional settings\n",
    "        marker = dict(\n",
    "            size=15,\n",
    "            symbol=markers[trade_index]\n",
    "        ),\n",
    "        hovertext=[f'Date Time: {row.datetime}<br />Action Index: {row.Index}<br />{\"Open\" if row.Index % 2 == 0 else \"Closed\"} at {row.price}<br />Profit: {row.profits}'\n",
    "                   for row in action_df.itertuples()],\n",
    "        hoverinfo='text'\n",
    "    ))\n",
    "\n",
    "title = f'{currency_pair} - Training Trades - {agent_type}'\n",
    "plot_graph(data, title, 'Date Time', 'Price')\n",
    "\n",
    "\n",
    "EXEC_END = time.time()\n",
    "time_taken(EXEC_END - EXEC_START)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chart: Training Trade Profits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXEC_START = time.time()\n",
    "\n",
    "y = trade_df['profits']\n",
    "\n",
    "data = []\n",
    "data.append(go.Scattergl(\n",
    "    x = [x for x in range(len(trade_df))],\n",
    "    y = y,\n",
    "    mode = 'lines',\n",
    "    name = f'Profits ({sum(y) :,.2f})'\n",
    "))\n",
    "\n",
    "title = f'{currency_pair} - Training Trade Profits - {agent_type}'\n",
    "plot_graph(data, title, '', 'Amount')\n",
    "\n",
    "\n",
    "EXEC_END = time.time()\n",
    "time_taken(EXEC_END - EXEC_START)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
